{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiLM1lW9Vca1",
        "outputId": "d76f2a1d-505c-4257-f75e-863b5cfef5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torch_geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Collecting torch_scatter\n",
            "  Using cached torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl\n",
            "Collecting torch_sparse\n",
            "  Using cached torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl\n",
            "Collecting torch_cluster\n",
            "  Using cached torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_spline_conv\n",
            "  Using cached torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.11/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.5.21)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "Building wheels for collected packages: torch_cluster, torch_spline_conv\n",
            "  Building wheel for torch_cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_cluster: filename=torch_cluster-1.6.3-cp311-cp311-linux_x86_64.whl size=739064 sha256=f56070d55a864df8ab755bbf9988f996f4124e965bf2a529c97cd3d7165dfbf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/de/7d/a4211822af99147b93800e9e204f0be21294e3c0b95b3b861a\n",
            "  Building wheel for torch_spline_conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_spline_conv: filename=torch_spline_conv-1.2.2-cp311-cp311-linux_x86_64.whl size=228695 sha256=83d55d2413438f6b84c82e94b4f5a228ada54d7efbad3fb0a9fe8de567c0f9b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/16/8a/a98b0173c4fbbc7aa1c4929b46d2eb08d1475c5c7b54e289b6\n",
            "Successfully built torch_cluster torch_spline_conv\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, torch_sparse, torch_cluster, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch_geometric, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch_cluster-1.6.3 torch_geometric-2.6.1 torch_scatter-2.1.2 torch_sparse-0.6.18 torch_spline_conv-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torch_geometric torch_scatter torch_sparse torch_cluster torch_spline_conv pandas numpy requests scikit-learn imbalanced-learn xgboost tensorflow shap lime matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwFCUoO7Tyh5"
      },
      "source": [
        "# Step 1: Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SjH1OVeWRM_h"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ETHERSCAN_API_KEY = \"V8RHS7P2YNSAHUY92CXVANVQK8MIYK95UQ\"\n",
        "BASE_URL = \"https://api.etherscan.io/api\"\n",
        "\n",
        "def get_transactions(address, start_block=0, end_block=99999999):\n",
        "    params = {\n",
        "        'module': 'account',\n",
        "        'action': 'txlist',\n",
        "        'address': address,\n",
        "        'startblock': start_block,\n",
        "        'endblock': end_block,\n",
        "        'sort': 'asc',\n",
        "        'apikey': ETHERSCAN_API_KEY\n",
        "    }\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "    return response.json()['result']\n",
        "\n",
        "normal_addresses = [\n",
        "    \"0x742d35Cc6634C0532925a3b844Bc454e4438f44e\",\n",
        "    \"0xDC76CD25977E0a5Ae17155770273aD58648900D3\",\n",
        "    \"0x267be1c1d684f78cb4f6a176c4911b741e4ffdc0\",\n",
        "]\n",
        "\n",
        "fraud_addresses = [\n",
        "    \"0x283aa3c6e0cf2c2d8f2c1c3b7603e7b4c8a9f2a6\",\n",
        "    \"0x6f46cf5569aefa1acc1009290c8e043747172d89\",\n",
        "]\n",
        "\n",
        "normal_txns = [get_transactions(addr) for addr in normal_addresses]\n",
        "fraud_txns = [get_transactions(addr) for addr in fraud_addresses]\n",
        "\n",
        "normal_df = pd.DataFrame([tx for sublist in normal_txns for tx in sublist])\n",
        "normal_df['is_fraud'] = 0\n",
        "fraud_df = pd.DataFrame([tx for sublist in fraud_txns for tx in sublist])\n",
        "fraud_df['is_fraud'] = 1\n",
        "df = pd.concat([normal_df, fraud_df], axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMDXUY9GULVz"
      },
      "source": [
        "# Step 2: Data Preprocessing & Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G8zNz34LUJOT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "\n",
        "def preprocess_data(df):\n",
        "    # Remove non-numeric columns for ML\n",
        "    non_numeric = ['hash', 'nonce', 'blockHash', 'from', 'to', 'input', 'contractAddress', 'cumulativeGasUsed', 'blockNumber', 'timeStamp', 'transactionIndex']\n",
        "    for col in non_numeric:\n",
        "        if col in df.columns:\n",
        "            df = df.drop(columns=[col])\n",
        "    # Convert timestamp first for features\n",
        "    if 'timeStamp' in df.columns:\n",
        "        df['timestamp'] = df['timeStamp'].apply(lambda x: datetime.fromtimestamp(int(x)))\n",
        "    else:\n",
        "        df['timestamp'] = pd.to_datetime('now')\n",
        "    # Feature engineering\n",
        "    df['value_eth'] = df['value'].astype(float) / 1e18\n",
        "    df['gas_price_gwei'] = df['gasPrice'].astype(float) / 1e9\n",
        "    df['gas_used'] = df['gasUsed'].astype(float)\n",
        "    df['gas_cost'] = df['gas_price_gwei'] * df['gas_used']\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
        "    df['value_gas_ratio'] = df['value_eth'] / (df['gas_cost'] + 1e-9)\n",
        "    # Add sender/receiver txn count (optional, but requires original from/to columns)\n",
        "    df['sender_txn_count'] = 1  # Dummy if dropped\n",
        "    df['receiver_txn_count'] = 1\n",
        "    # Select features\n",
        "    features = [\n",
        "        'value_eth', 'gas_price_gwei', 'gas_used', 'gas_cost',\n",
        "        'hour_of_day', 'day_of_week', 'is_weekend', 'value_gas_ratio',\n",
        "        'sender_txn_count', 'receiver_txn_count'\n",
        "    ]\n",
        "    X = df[features]\n",
        "    y = df['is_fraud']\n",
        "    return X, y\n",
        "\n",
        "X, y = preprocess_data(df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wyfTt1vUOmk"
      },
      "source": [
        "# Step 3: Class Balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Eplzavz8USHZ"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "over = SMOTE(sampling_strategy=0.1, random_state=42)\n",
        "under = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
        "resample_pipeline = Pipeline([\n",
        "    ('o', over),\n",
        "    ('u', under)\n",
        "])\n",
        "X_train_res, y_train_res = resample_pipeline.fit_resample(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhJXoMPRUUVL"
      },
      "source": [
        "# Step 4: Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85aUdd3JUZKd"
      },
      "source": [
        "## XGBoost Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI42bpqqUcVG",
        "outputId": "84e72188-6160-41c1-8fac-df7a241d8955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      4159\n",
            "           1       0.36      0.96      0.52       100\n",
            "\n",
            "    accuracy                           0.96      4259\n",
            "   macro avg       0.68      0.96      0.75      4259\n",
            "weighted avg       0.98      0.96      0.97      4259\n",
            "\n",
            "ROC-AUC: 0.9846585717720606\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    scale_pos_weight=(len(y_train_res) - sum(y_train_res)) / sum(y_train_res)\n",
        ")\n",
        "xgb_model.fit(X_train_scaled, y_train_res)\n",
        "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "y_proba_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "print(\"XGBoost Performance:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_xgb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrvcmrpZUeiO"
      },
      "source": [
        "## LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6nXuLvIoUhep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77c6859-eb37-4672-9042-058cb10418e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - accuracy: 0.5311 - loss: 1.2405 - val_accuracy: 0.8612 - val_loss: 0.4739\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.8889 - loss: 0.5771 - val_accuracy: 0.8868 - val_loss: 0.4097\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9021 - loss: 0.5041 - val_accuracy: 0.8959 - val_loss: 0.3096\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.9033 - loss: 0.4391 - val_accuracy: 0.8760 - val_loss: 0.3347\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - accuracy: 0.9239 - loss: 0.3440 - val_accuracy: 0.9009 - val_loss: 0.2959\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.9339 - loss: 0.3348 - val_accuracy: 0.9302 - val_loss: 0.2119\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9328 - loss: 0.3067 - val_accuracy: 0.9204 - val_loss: 0.2610\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9473 - loss: 0.2997 - val_accuracy: 0.9490 - val_loss: 0.1503\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9530 - loss: 0.2501 - val_accuracy: 0.9309 - val_loss: 0.1818\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9427 - loss: 0.2546 - val_accuracy: 0.9274 - val_loss: 0.1444\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "LSTM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96      4157\n",
            "           1       0.24      0.98      0.39       100\n",
            "\n",
            "    accuracy                           0.93      4257\n",
            "   macro avg       0.62      0.95      0.67      4257\n",
            "weighted avg       0.98      0.93      0.95      4257\n",
            "\n",
            "ROC-AUC: 0.9949386576858311\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# We create sequences using only numeric features\n",
        "def create_sequences(X, y, sequence_length=10):\n",
        "    sequences, labels = [], []\n",
        "    for i in range(len(X) - sequence_length):\n",
        "        seq = X.iloc[i:i+sequence_length].values\n",
        "        label = y.iloc[i+sequence_length-1]\n",
        "        sequences.append(seq)\n",
        "        labels.append(label)\n",
        "    return np.array(sequences), np.array(labels)\n",
        "\n",
        "X_sequences, y_sequences = create_sequences(X, y)\n",
        "X_seq_train, X_seq_test, y_seq_train, y_seq_test = train_test_split(\n",
        "    X_sequences, y_sequences, test_size=0.2, random_state=42, stratify=y_sequences\n",
        ")\n",
        "# Resample: flatten to 2D, resample, then reshape\n",
        "X_seq_train_2d = X_seq_train.reshape(X_seq_train.shape[0], -1)\n",
        "X_seq_train_res, y_seq_train_res = resample_pipeline.fit_resample(X_seq_train_2d, y_seq_train)\n",
        "X_seq_train_res = X_seq_train_res.reshape(-1, X_seq_train.shape[1], X_seq_train.shape[2])\n",
        "\n",
        "# Scale\n",
        "seq_scaler = StandardScaler()\n",
        "X_seq_train_res_flat = X_seq_train_res.reshape(-1, X_seq_train_res.shape[2])\n",
        "X_seq_train_scaled = seq_scaler.fit_transform(X_seq_train_res_flat).reshape(X_seq_train_res.shape)\n",
        "X_seq_test_flat = X_seq_test.reshape(-1, X_seq_test.shape[2])\n",
        "X_seq_test_scaled = seq_scaler.transform(X_seq_test_flat).reshape(X_seq_test.shape)\n",
        "\n",
        "# LSTM Model\n",
        "lstm_model = Sequential([\n",
        "    Masking(mask_value=0., input_shape=(X_seq_train_scaled.shape[1], X_seq_train_scaled.shape[2])),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "lstm_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "history_lstm = lstm_model.fit(\n",
        "    X_seq_train_scaled, y_seq_train_res,\n",
        "    validation_data=(X_seq_test_scaled, y_seq_test),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    class_weight={0: 1., 1: 5.}\n",
        ")\n",
        "y_pred_lstm = (lstm_model.predict(X_seq_test_scaled) > 0.5).astype(int)\n",
        "y_proba_lstm = lstm_model.predict(X_seq_test_scaled)\n",
        "print(\"LSTM Performance:\")\n",
        "print(classification_report(y_seq_test, y_pred_lstm))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_seq_test, y_proba_lstm))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SHIwooGUjB5"
      },
      "source": [
        "## CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T31ipUuWUlwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276f7975-1c2a-4249-a907-c544c6358757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5299 - loss: 1.3783 - val_accuracy: 0.4141 - val_loss: 0.7242\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7109 - loss: 0.8471 - val_accuracy: 0.8710 - val_loss: 0.3767\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8970 - loss: 0.5151 - val_accuracy: 0.9204 - val_loss: 0.2795\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9449 - loss: 0.3504 - val_accuracy: 0.9563 - val_loss: 0.1715\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.2677 - val_accuracy: 0.9542 - val_loss: 0.1641\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9582 - loss: 0.2435 - val_accuracy: 0.9295 - val_loss: 0.2256\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9587 - loss: 0.2152 - val_accuracy: 0.9523 - val_loss: 0.1470\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9616 - loss: 0.2165 - val_accuracy: 0.9568 - val_loss: 0.1312\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9643 - loss: 0.2061 - val_accuracy: 0.9652 - val_loss: 0.1000\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9710 - loss: 0.1622 - val_accuracy: 0.9490 - val_loss: 0.1458\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "CNN Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97      4157\n",
            "           1       0.31      0.97      0.47       100\n",
            "\n",
            "    accuracy                           0.95      4257\n",
            "   macro avg       0.66      0.96      0.72      4257\n",
            "weighted avg       0.98      0.95      0.96      4257\n",
            "\n",
            "ROC-AUC: 0.9925643492903536\n"
          ]
        }
      ],
      "source": [
        "cnn_model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_seq_train_scaled.shape[1], X_seq_train_scaled.shape[2])),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "cnn_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "history_cnn = cnn_model.fit(\n",
        "    X_seq_train_scaled, y_seq_train_res,\n",
        "    validation_data=(X_seq_test_scaled, y_seq_test),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    class_weight={0: 1., 1: 5.}\n",
        ")\n",
        "y_pred_cnn = (cnn_model.predict(X_seq_test_scaled) > 0.5).astype(int)\n",
        "y_proba_cnn = cnn_model.predict(X_seq_test_scaled)\n",
        "print(\"CNN Performance:\")\n",
        "print(classification_report(y_seq_test, y_pred_cnn))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_seq_test, y_proba_cnn))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErvPT7hGB6_T"
      },
      "source": [
        "## GCN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yEmAb9iLCC9w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "9165e6a5-9f6e-4e3a-c048-0018b6f2acc8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Column not found: value_eth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-57120774ef05>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'from'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recv_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'to'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'from'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_eth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recv_value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'to'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_eth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'recv_count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sent_value'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'recv_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1949\u001b[0m                 \u001b[0;34m\"Use a list instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m             )\n\u001b[0;32m-> 1951\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Column not found: value_eth'"
          ]
        }
      ],
      "source": [
        "# Cell: Build address graph (add before GNN model code)\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Build mapping for addresses\n",
        "addresses = pd.concat([df['from'], df['to']]).unique()\n",
        "addr2idx = {addr: idx for idx, addr in enumerate(addresses)}\n",
        "\n",
        "# Create edge index (source and target address indices)\n",
        "edges = torch.tensor([\n",
        "    [addr2idx[f], addr2idx[t]]\n",
        "    for f, t in zip(df['from'], df['to'])\n",
        "    if f in addr2idx and t in addr2idx\n",
        "], dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Node features: e.g. total sent, received, and count of txns per address\n",
        "feat_df = pd.DataFrame({'address': addresses})\n",
        "feat_df['sent_count'] = feat_df['address'].map(df['from'].value_counts()).fillna(0)\n",
        "feat_df['recv_count'] = feat_df['address'].map(df['to'].value_counts()).fillna(0)\n",
        "feat_df['sent_value'] = feat_df['address'].map(df.groupby('from')['value_eth'].sum()).fillna(0)\n",
        "feat_df['recv_value'] = feat_df['address'].map(df.groupby('to')['value_eth'].sum()).fillna(0)\n",
        "x = torch.tensor(feat_df[['sent_count','recv_count','sent_value','recv_value']].values, dtype=torch.float)\n",
        "\n",
        "# Node labels: fraud = 1 if in fraud list, else 0\n",
        "feat_df['label'] = feat_df['address'].apply(lambda x: 1 if x in fraud_addresses else 0)\n",
        "y = torch.tensor(feat_df['label'].values, dtype=torch.long)\n",
        "\n",
        "# Cell: Define and train GCN\n",
        "class SimpleGCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Prepare data object\n",
        "data = Data(x=x, edge_index=edges, y=y)\n",
        "\n",
        "# Train/test split: use known frauds/non-frauds as train, rest as test\n",
        "mask = feat_df['address'].isin(normal_addresses + fraud_addresses)\n",
        "train_mask = torch.tensor(mask, dtype=torch.bool)\n",
        "test_mask = ~train_mask\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SimpleGCN(x.shape[1], 16, 2).to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = loss_fn(out[train_mask], data.y[train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(data.x, data.edge_index)\n",
        "    pred = logits.argmax(dim=1)\n",
        "    from sklearn.metrics import classification_report\n",
        "    print(\"GCN on known addresses:\")\n",
        "    print(classification_report(data.y[test_mask].cpu(), pred[test_mask].cpu()))\n",
        "    gcn_probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T677GzR9CU97"
      },
      "source": [
        "## Ensembling Your Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcSunLoPCW6P"
      },
      "outputs": [],
      "source": [
        "# Cell: Ensemble model predictions\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Prepare ensemble features (align test sets)\n",
        "# Note: You must align the indices between test sets. Here, we use only addresses present in all outputs.\n",
        "test_addresses = set(df.iloc[y_test.index]['from']) & set(feat_df.loc[test_mask, 'address'])\n",
        "ensemble_idx = [feat_df.index[feat_df['address'] == addr][0] for addr in test_addresses]\n",
        "\n",
        "# Get probabilities (adjust as needed for your data alignment)\n",
        "ensemble_X = np.vstack([\n",
        "    y_proba_xgb[:len(ensemble_idx)],\n",
        "    y_proba_lstm[:len(ensemble_idx)],\n",
        "    y_proba_cnn[:len(ensemble_idx)],\n",
        "    gcn_probs[ensemble_idx]\n",
        "]).T\n",
        "\n",
        "# Use known labels for these addresses\n",
        "ensemble_y = y.iloc[y_test.index][:len(ensemble_idx)].values\n",
        "\n",
        "# Train/test split for stacking (or do cross-validation)\n",
        "X_ens_train, X_ens_test, y_ens_train, y_ens_test = train_test_split(ensemble_X, ensemble_y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_ensemble = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_ensemble.fit(X_ens_train, y_ens_train)\n",
        "y_ensemble_pred = rf_ensemble.predict(X_ens_test)\n",
        "y_ensemble_proba = rf_ensemble.predict_proba(X_ens_test)[:, 1]\n",
        "\n",
        "print(\"Ensemble Performance:\")\n",
        "print(classification_report(y_ens_test, y_ensemble_pred))\n",
        "print(\"Ensemble ROC-AUC:\", roc_auc_score(y_ens_test, y_ensemble_proba))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbBQj62zUoeq"
      },
      "source": [
        "# Step 5: Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9O8A45dCvDf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "\n",
        "def plot_roc_curve(y_true, y_proba, model_name, color=None):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})', color=color)\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "def plot_pr_curve(y_true, y_proba, model_name, color=None):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
        "    ap = average_precision_score(y_true, y_proba)\n",
        "    plt.plot(recall, precision, label=f'{model_name} (AP = {ap:.2f})', color=color)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "# === Main plotting section ===\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_roc_curve(y_test, y_proba_xgb, 'XGBoost', color='C0')\n",
        "plot_roc_curve(y_seq_test, y_proba_lstm, 'LSTM', color='C1')\n",
        "plot_roc_curve(y_seq_test, y_proba_cnn, 'CNN', color='C2')\n",
        "# Add GCN if available\n",
        "if 'gcn_probs' in globals() and 'test_mask' in globals():\n",
        "    # Use only test_mask indices for evaluation\n",
        "    gcn_y_true = y[test_mask].cpu().numpy() if hasattr(y[test_mask], 'cpu') else y[test_mask].values\n",
        "    gcn_y_proba = gcn_probs[test_mask] if hasattr(gcn_probs, '__getitem__') else gcn_probs\n",
        "    plot_roc_curve(gcn_y_true, gcn_y_proba, 'GCN (GNN)', color='C3')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_pr_curve(y_test, y_proba_xgb, 'XGBoost', color='C0')\n",
        "plot_pr_curve(y_seq_test, y_proba_lstm, 'LSTM', color='C1')\n",
        "plot_pr_curve(y_seq_test, y_proba_cnn, 'CNN', color='C2')\n",
        "if 'gcn_probs' in globals() and 'test_mask' in globals():\n",
        "    plot_pr_curve(gcn_y_true, gcn_y_proba, 'GCN (GNN)', color='C3')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmbDkUwTUoQv"
      },
      "source": [
        "# Step 6: Explainability with SHAP and LIME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJsavDZgVDEW"
      },
      "source": [
        "# SHAP Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmkpxW5JVGOD"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "explainer_xgb = shap.TreeExplainer(xgb_model)\n",
        "shap_values_xgb = explainer_xgb.shap_values(X_test_scaled)\n",
        "shap.summary_plot(shap_values_xgb, X_test_scaled, feature_names=X.columns)\n",
        "shap.force_plot(explainer_xgb.expected_value, shap_values_xgb[0, :], X_test_scaled[0, :], feature_names=X.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0p49hN2VKbk"
      },
      "source": [
        "## LIME Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr1ndTElVIKl"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_train_scaled,\n",
        "    feature_names=X.columns,\n",
        "    class_names=['Normal', 'Fraud'],\n",
        "    mode='classification'\n",
        ")\n",
        "exp = explainer_lime.explain_instance(\n",
        "    X_test_scaled[0],\n",
        "    xgb_model.predict_proba,\n",
        "    num_features=10\n",
        ")\n",
        "exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QYc6yGRVQ-A"
      },
      "source": [
        "# Step 7: Comparison & Reporting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2ZqdNq2VTIi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
        "\n",
        "def evaluate_model(y_true, y_pred, y_proba, model_name):\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'F1-Score': f1_score(y_true, y_pred, zero_division=0),\n",
        "        'ROC-AUC': roc_auc_score(y_true, y_proba)\n",
        "    }\n",
        "\n",
        "# Gather results\n",
        "results = [\n",
        "    evaluate_model(y_test, y_pred_xgb, y_proba_xgb, 'XGBoost'),\n",
        "    evaluate_model(y_seq_test, y_pred_lstm, y_proba_lstm, 'LSTM'),\n",
        "    evaluate_model(y_seq_test, y_pred_cnn, y_proba_cnn, 'CNN')\n",
        "]\n",
        "\n",
        "# Add GCN/GNN if available\n",
        "if 'gcn_probs' in globals() and 'test_mask' in globals():\n",
        "    gcn_y_true = y[test_mask].cpu().numpy() if hasattr(y[test_mask], 'cpu') else y[test_mask].values\n",
        "    gcn_y_pred = (gcn_probs[test_mask] > 0.5).astype(int) if hasattr(gcn_probs, '__getitem__') else (gcn_probs > 0.5).astype(int)\n",
        "    gcn_y_proba = gcn_probs[test_mask] if hasattr(gcn_probs, '__getitem__') else gcn_probs\n",
        "    results.append(evaluate_model(gcn_y_true, gcn_y_pred, gcn_y_proba, 'GCN (GNN)'))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(results_df)\n",
        "\n",
        "# Visual comparison\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.bar(results_df['Model'], results_df[metric])\n",
        "    plt.title(metric)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.xticks(rotation=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}